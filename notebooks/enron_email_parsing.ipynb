{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import email\n",
    "import os\n",
    "from stop_words import get_stop_words\n",
    "from gensim import corpora, models, utils\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import clean_html\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data definition\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "en_stop = get_stop_words('en')\n",
    "en_stop.append(\"com\")\n",
    "en_stop.append(\"www\")\n",
    "en_stop.append(\"[IMAGE]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and extract exmail body\n",
    "root_dir = os.path.join(\"C:\", os.sep, \"dataset\", \"enron-dataset\")\n",
    "author_name = [ os.path.join(root_dir, dir) for dir in os.listdir(root_dir) \n",
    "               if os.path.isdir(os.path.join(root_dir, dir)) ]\n",
    "\n",
    "msg = {}\n",
    "for auth_path in author_name:\n",
    "    # Get list of email in inbox folder\n",
    "    try: # try if inbox folder exist\n",
    "        inbox_path = os.path.join(auth_path, \"inbox\")\n",
    "        email_file_name = [ os.path.join(inbox_path, file) for file in os.listdir(inbox_path) \n",
    "                                       if os.path.isfile(os.path.join(inbox_path, file)) ]\n",
    "        for file in email_file_name:\n",
    "            with open(file) as fp:\n",
    "                # Create a text/plain message\n",
    "                message = email.message_from_file(fp)\n",
    "                #print(message._payload)\n",
    "            msg[file] = message._payload\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "key_list = list(msg.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Message-ID', '<692316.1075842025145.JavaMail.evans@thyme>'),\n",
       " ('Date', 'Wed, 6 Feb 2002 11:57:35 -0800 (PST)'),\n",
       " ('From', 'danielle.marcinkowski@enron.com'),\n",
       " ('To', 'john.zufferli@enron.com'),\n",
       " ('Subject', 'IHS Accumap'),\n",
       " ('Cc', 'dan.dietrich@enron.com'),\n",
       " ('Mime-Version', '1.0'),\n",
       " ('Content-Type', 'text/plain; charset=us-ascii'),\n",
       " ('Content-Transfer-Encoding', '7bit'),\n",
       " ('Bcc', 'dan.dietrich@enron.com'),\n",
       " ('X-From',\n",
       "  'Marcinkowski, Danielle </O=ENRON/OU=NA/CN=RECIPIENTS/CN=DMARCIN>'),\n",
       " ('X-To', 'Zufferli, John </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Jzuffer>'),\n",
       " ('X-cc', 'Dietrich, Dan </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Ddietri>'),\n",
       " ('X-bcc', ''),\n",
       " ('X-Folder', '\\\\ExMerge - Zufferli, John\\\\Inbox'),\n",
       " ('X-Origin', 'ZUFFERLI-J'),\n",
       " ('X-FileName', 'john zufferli 6-26-02.PST')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message._headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John:\n",
      "\n",
      "Do you need Accumap day one?  Carmen said that it had not been renewed so do you have access to it now?  \n",
      "If you do need an account how many and for who?\n",
      "\n",
      "thanks,\n",
      "\n",
      "Danielle \n"
     ]
    }
   ],
   "source": [
    "print(message._payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team\n",
      "FYI\n",
      "\n",
      "Sheri\n",
      "The 3 SME's that have already committed to being on film need to be keep in the lope regarding the timeline. Also check with these 2 SME's for additional candidates (i.e. check with Mark Reese to see if Lamar Frazier would be interested). I would like to be conferenced in on the media calls & meetings. Also cc me on their emails or forward to me  their  emails. This will keep me in the loop. Thanks\n",
      "\n",
      "Phillip\n",
      "If you have some additional people in mind, we need them identified as soon as possible. Thanks\n",
      "\n",
      "Cheers\n",
      "Kirk\n",
      "---------------------- Forwarded by Kirk McDaniel/HOU/EES on 11/27/2001 10:04 AM ---------------------------\n",
      "\n",
      "\n",
      "sheri.a.righi@accenture.com on 11/27/2001 09:09:46 AM\n",
      "To:\tkmcdani@enron.com\n",
      "cc:\tdonald.l.barnhart@accenture.com \n",
      "Subject:\tRE: Updates to our Video Production Timeframes and Scope\n",
      "\n",
      "\n",
      "Kirk -\n",
      "\n",
      "Thank you for helping us work towards sign-off from Enron Legal. Seeing as\n",
      "you haven't been closely involved, I thought you'd like an update on our\n",
      "media production tasks.\n",
      "\n",
      "As you know, we are completing our planning phase for the production of the\n",
      "storyline scripts. Our media vendor, Cramer, has been extremely helpful and\n",
      "enjoyable to work with.  Below is an email from Steve, the director for our\n",
      "storyline video, explaining where we are in the production process.\n",
      "\n",
      "Have a good day!\n",
      "\n",
      "\n",
      "Sheri A. Righi\n",
      "Accenture\n",
      "Human Performance Service Line\n",
      "Hartford - One Financial Plaza\n",
      "Direct Dial: 860 756 2245\n",
      "VPN & Octel: 765 2245\n",
      "e-mail: sheri.a.righi@Accenture.com\n",
      "\n",
      "\n",
      "----- Forwarded by Sheri A. Righi/Internal/Accenture on 11/27/2001 09:05 AM\n",
      "-----\n",
      "\n",
      "            Steve Johnson\n",
      "            <SJohnson@crameronline.co        To:     Sheri A. Righi/Internal/Accenture@Accenture\n",
      "            m>                               cc:     Chris Ciotoli <CCiotoli@crameronline.com>\n",
      "                                             Subject:     RE: Updates to our Video Production Timeframes and Scope\n",
      "            11/26/2001 11:27 AM\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hey Sheri,\n",
      "I hope you had a great Thanksgiving! I can't believe it's over\n",
      "already! Anyway...we've shuffled the schedule around, securing the 6th and\n",
      "7th of\n",
      "December for the shoot in the studio. We're working on finalizing the\n",
      "edit dates to reflect that shift. Chris is moving to hold all talent for\n",
      "those dates.\n",
      "\n",
      "I guess it's now in the hands of legal! As soon as we confirm the edit\n",
      "suite\n",
      "availability\n",
      "we'll revise and post the new schedule. We're scheduled for our weekly call\n",
      "tomorrow but if\n",
      "anything comes up just give me a buzz!\n",
      "Thanks Sheri!\n",
      "Steve\n",
      "\n",
      "\n",
      "-----Original Message-----\n",
      "From: sheri.a.righi@accenture.com [mailto:sheri.a.righi@accenture.com]\n",
      "Sent: Wednesday, November 21, 2001 1:42 PM\n",
      "To: SJohnson@crameronline.com; CCiotoli@crameronline.com\n",
      "Cc: mery.l.brown@accenture.com; donald.l.barnhart@accenture.com;\n",
      "jonathan.o.stahl@accenture.com\n",
      "Subject: Updates to our Video Production Timeframes and Scope\n",
      "\n",
      "\n",
      "Hello Steve and Chris -\n",
      "\n",
      "Recently, there were changes to the overall number of our scenarios in our\n",
      "simulation. There will be seven scenarios versus the nine we have been\n",
      "discussing. These changes result in:\n",
      "        Deletion of 2 intro and 2 exit videos\n",
      "        Deletion of six interview questions (see more detail below)\n",
      "        No additional characters. We will still need all characters (and\n",
      "        talent) that we have casted for.\n",
      "\n",
      "Laura has been working with John to make the required edits to the scripts.\n",
      "We have recieved today (mid-day).\n",
      "\n",
      "Based on our last discussion, I'd like to recommend we set the date for our\n",
      "shoot for the end of the first week in Dec. Specifically, Dec. 6th and 7th.\n",
      "This recommendation is based on the response I received from our project\n",
      "manager in regards to the time it will take to have Legal review our\n",
      "scripts.\n",
      "\n",
      "Please let me know if you have any questions. Thank you and have a\n",
      "wonderful Thanksgiving!\n",
      "\n",
      "Sheri A. Righi\n",
      "Accenture\n",
      "Human Performance Service Line\n",
      "Hartford - One Financial Plaza\n",
      "Direct Dial: 860 756 2245\n",
      "VPN & Octel: 765 2245\n",
      "e-mail: sheri.a.righi@Accenture.com\n",
      "\n",
      "\n",
      "----- Forwarded by Sheri A. Righi/Internal/Accenture on 11/21/2001 01:30 PM\n",
      "-----\n",
      "\n",
      "\n",
      "            Laura A. de la Torre\n",
      "\n",
      "                                         To:     Mery L.\n",
      "Brown/Internal/Accenture@Accenture, Sheri A.\n",
      "            11/20/2001 05:35 PM          Righi/Internal/Accenture@Accenture\n",
      "\n",
      "                                         cc:\n",
      "\n",
      "                                         Subject:     Conversion and\n",
      "Arbitrage Q&A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "These are the changes resulting from omitting conversion and arbitrage\n",
      "\n",
      "From Scenario 6 Conversion:\n",
      "\n",
      "-delete Q # 1, 2, 6\n",
      "-move Q #3 to scenario 5 (power plant) and make the Q be for the financial\n",
      "trader, Garcia\n",
      "-move Q #4 and #5 to scenario 9 (storage) and make them be for the\n",
      "structurer, Chen\n",
      "\n",
      "From Scenario 7 Arbitrage:\n",
      "\n",
      "-delete Q #1, 2, 3\n",
      "-move Q#4 to scenario 9 (storage) and keep it as a Q for the physical\n",
      "trader (Rick Lee)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Laura de la Torre\n",
      "Accenture\n",
      "Resources\n",
      "Houston, Texas\n",
      "Direct Dial  713.837.2133\n",
      "Octel  83 / 72133\n",
      "\n",
      "\n",
      "\n",
      "This message is for the designated recipient only and may contain\n",
      "privileged, proprietary, or otherwise private information.  If you have\n",
      "received it in error, please notify the sender immediately and delete the\n",
      "original.  Any other use of the email by you is prohibited.\n",
      "\n",
      "\n",
      "\n",
      "This message is for the designated recipient only and may contain\n",
      "privileged, proprietary, or otherwise private information.  If you have\n",
      "received it in error, please notify the sender immediately and delete the\n",
      "original.  Any other use of the email by you is prohibited.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(msg[key_list[46]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message pre processing\n",
    "\n",
    "cleaned_msg = {}\n",
    "max_count = 100\n",
    "count = 0\n",
    "for key, message in msg.items():\n",
    "    #Remove the original message from the body\n",
    "    clean_body = message[0:message.find(\"-----Original Message-----\")]\n",
    "    # Remove all URL links\n",
    "    body_linkless = re.sub(r\"http\\S+\", \"\", clean_body)\n",
    "    # Remove html code\n",
    "    soup = BeautifulSoup(body_linkless)\n",
    "    body_linkless_html = soup.get_text()\n",
    "    # Remove [image]\n",
    "    body_linkless_html_image = body_linkless_html.replace(\"[IMAGE]\", \"\")\n",
    "    cleaned_msg[key] = body_linkless_html_image\n",
    "    count += 1\n",
    "    if count > max_count:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, mes in cleaned_msg.items():\n",
    "    print(key)\n",
    "    print(mes)\n",
    "    print(\"OTHER EMAIL _______________________________\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency_filter(texts, count_threshold):\n",
    "    \"\"\"Remove word whose frequency is less than a count threshold\n",
    "    \"\"\"\n",
    "\n",
    "    frequency = defaultdict(int)\n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency[token] += 1\n",
    "\n",
    "    return [[token for token in text if frequency[token] > count_threshold] for text in texts ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocess\n",
    "processed_msg = {}\n",
    "raw_message = []\n",
    "for key, document in cleaned_msg.items():\n",
    "    # raw = document.lower() # use less with simple token\n",
    "    tokens = utils.simple_preprocess(document)\n",
    "    # print(tokens)\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if (not i in en_stop)]\n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    print(key)\n",
    "    # Lemmatize ?\n",
    "    print(stemmed_tokens)\n",
    "    # Remove tokens that not appear enough in the corpus\n",
    "    # remove words that appear only once\n",
    "    st_tokens = word_frequency_filter(stemmed_tokens, 2)\n",
    "    print(\"-\"*100)\n",
    "    processed_msg[key] = stemmed_tokens\n",
    "    \n",
    "    raw_message.append(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = corpora.Dictionary([ email for _, email in processed_msg.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_topic = 7\n",
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(text) for _, text in processed_msg.items()]\n",
    "\n",
    "# generate LDA model\n",
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=number_topic, id2word=dictionary, passes=100)\n",
    "\n",
    "ldamodel.print_topics(num_topics = number_topic, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, c in enumerate(ldamodel[corpus]):\n",
    "    print(\"document number : {}\".format(count))\n",
    "    print(\"Topics number      : \", c[0][0])\n",
    "    print(ldamodel.print_topic(c[0][0]))\n",
    "    print(\"similarity index : {}\".format(c[0][1]))\n",
    "    print(\"------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for count, c in enumerate(ldamodel[corpus]):\n",
    "    print(\"document number : {}\".format(count))\n",
    "    print(cleaned_msg[key_list[count]])\n",
    "    print(\"Topics number      : \", c[0])\n",
    "    print(ldamodel.print_topic(c[0][0]))\n",
    "    print(\"similarity index : {}\".format(c[0][1]))\n",
    "    print(\"------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim.prepare(topic_model=ldamodel, corpus=corpus, dictionary=dictionary)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.get_document_topics(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.get_topic_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topic = 0\n",
    "for count, c in enumerate(ldamodel[corpus]):\n",
    "    if c[0][0] == topic:\n",
    "        print(\"document number : {}\".format(count))\n",
    "        print(cleaned_msg[key_list[count]])\n",
    "        print(\"Topics number      : \", c[0])\n",
    "        print(ldamodel.print_topic(c[0][0]))\n",
    "        print(\"similarity index : {}\".format(c[0][1]))\n",
    "        print(\"------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col': ['a', 'b', 'c', 'D', 'EEE']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = {\"col\": [\"a\", \"b\", \"c\", \"D\", \"EEE\"]}\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col\n",
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    D\n",
       "4  EEE"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = pd.DataFrame(aa)\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "édfjdkdjdé\n"
     ]
    }
   ],
   "source": [
    "def ll(s):\n",
    "    return s.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      a\n",
       "1      b\n",
       "2      c\n",
       "3      d\n",
       "4    eee\n",
       "Name: col, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb[\"col\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col\n",
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    D\n",
       "4  EEE"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
